{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x1001000/Colab-Notebooks/blob/main/Hello_OpenAI_API_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI API key"
      ],
      "metadata": {
        "id": "Roo7TW5NP4aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = getpass('Your secret API key: ')"
      ],
      "metadata": {
        "id": "zKLTozSoGyFw",
        "outputId": "23df0f77-47c0-49e5-baa7-bdba93b24319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your secret API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python library for the OpenAI API"
      ],
      "metadata": {
        "id": "LMU9PZUcASsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NxLs7m56Ho8",
        "outputId": "4c914f49-6e0c-448e-99c2-dbeb9104f707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/221.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.__version__"
      ],
      "metadata": {
        "id": "VSZURvcBGHJ5",
        "outputId": "4e03f6c7-d826-4e79-f68d-31bc47074792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.3.7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "uVzScdXjS4vM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft5oSZtpPFPy"
      },
      "source": [
        "# Models\n",
        "- https://platform.openai.com/docs/models\n",
        "- https://platform.openai.com/docs/api-reference/models\n",
        "- GET https://api.openai.com/v1/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXPSz4x8zpiu",
        "outputId": "87240910-7416-40df-9ff8-7e199bd2c00c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ada',\n",
              " 'ada-code-search-code',\n",
              " 'ada-code-search-text',\n",
              " 'ada-search-document',\n",
              " 'ada-search-query',\n",
              " 'ada-similarity',\n",
              " 'babbage',\n",
              " 'babbage-002',\n",
              " 'babbage-code-search-code',\n",
              " 'babbage-code-search-text',\n",
              " 'babbage-search-document',\n",
              " 'babbage-search-query',\n",
              " 'babbage-similarity',\n",
              " 'code-davinci-edit-001',\n",
              " 'code-search-ada-code-001',\n",
              " 'code-search-ada-text-001',\n",
              " 'code-search-babbage-code-001',\n",
              " 'code-search-babbage-text-001',\n",
              " 'curie',\n",
              " 'curie-instruct-beta',\n",
              " 'curie-search-document',\n",
              " 'curie-search-query',\n",
              " 'curie-similarity',\n",
              " 'dall-e-2',\n",
              " 'dall-e-3',\n",
              " 'davinci',\n",
              " 'davinci-002',\n",
              " 'davinci-instruct-beta',\n",
              " 'davinci-search-document',\n",
              " 'davinci-search-query',\n",
              " 'davinci-similarity',\n",
              " 'gpt-3.5-turbo',\n",
              " 'gpt-3.5-turbo-0301',\n",
              " 'gpt-3.5-turbo-0613',\n",
              " 'gpt-3.5-turbo-1106',\n",
              " 'gpt-3.5-turbo-16k',\n",
              " 'gpt-3.5-turbo-16k-0613',\n",
              " 'gpt-3.5-turbo-instruct',\n",
              " 'gpt-3.5-turbo-instruct-0914',\n",
              " 'gpt-4',\n",
              " 'gpt-4-0314',\n",
              " 'gpt-4-0613',\n",
              " 'gpt-4-1106-preview',\n",
              " 'gpt-4-vision-preview',\n",
              " 'text-ada-001',\n",
              " 'text-babbage-001',\n",
              " 'text-curie-001',\n",
              " 'text-davinci-001',\n",
              " 'text-davinci-002',\n",
              " 'text-davinci-003',\n",
              " 'text-davinci-edit-001',\n",
              " 'text-embedding-ada-002',\n",
              " 'text-search-ada-doc-001',\n",
              " 'text-search-ada-query-001',\n",
              " 'text-search-babbage-doc-001',\n",
              " 'text-search-babbage-query-001',\n",
              " 'text-search-curie-doc-001',\n",
              " 'text-search-curie-query-001',\n",
              " 'text-search-davinci-doc-001',\n",
              " 'text-search-davinci-query-001',\n",
              " 'text-similarity-ada-001',\n",
              " 'text-similarity-babbage-001',\n",
              " 'text-similarity-curie-001',\n",
              " 'text-similarity-davinci-001',\n",
              " 'tts-1',\n",
              " 'tts-1-1106',\n",
              " 'tts-1-hd',\n",
              " 'tts-1-hd-1106',\n",
              " 'whisper-1']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "models = client.models.list().data\n",
        "sorted([model.id for model in models])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfnuUPTV0MF9"
      },
      "source": [
        "# Completions API\n",
        "- https://platform.openai.com/docs/guides/text-generation/completions-api\n",
        "- https://platform.openai.com/docs/api-reference/completions\n",
        "- POST https://api.openai.com/v1/completions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFdApCSs9KBj",
        "outputId": "60ea3365-e5d1-40f4-dfc5-2af0eb936f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "蔣萬安（1903年－1997年）是中華民國第三任總統，也是中國共產黨的創始人之一。他曾於1949年就任中華民國總\n"
          ]
        }
      ],
      "source": [
        "completion = client.completions.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt='誰是蔣萬安？',\n",
        "  temperature=0.5,\n",
        "  max_tokens=100,\n",
        "  top_p=0.3,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.0\n",
        ")\n",
        "\n",
        "print(completion.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il_hQDcdowVV",
        "outputId": "8759d4bb-ccd1-4ab4-e86f-3a42959e6e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "蔣萬安（1903年－1997年）是中華民國第三任總統，也是中國共產黨的創始人之一。他曾於1949年建立中華民國政\n"
          ]
        }
      ],
      "source": [
        "import requests, json\n",
        "openai_api = 'https://api.openai.com/v1/completions'\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\"}\n",
        "payload = json.dumps({\n",
        "  \"model\": \"text-davinci-003\",\n",
        "  \"prompt\": \"誰是蔣萬安\",\n",
        "  \"temperature\": 0.5,\n",
        "  \"max_tokens\": 100,\n",
        "  \"top_p\": 0.3,\n",
        "  \"frequency_penalty\": 0.5,\n",
        "  \"presence_penalty\": 0.0})\n",
        "\n",
        "r = requests.post(openai_api, headers=headers, data=payload)\n",
        "\n",
        "print(json.loads(r.text)['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5IaVLoNypx2"
      },
      "source": [
        "# Chat Completions API\n",
        "- https://platform.openai.com/docs/guides/text-generation/chat-completions-api\n",
        "- https://platform.openai.com/docs/api-reference/chat\n",
        "- POST https://api.openai.com/v1/chat/completions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmaEm2XV3tV7",
        "outputId": "1206b76d-9497-4b31-e822-f31b03e499d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}