{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x1001000/Colab-Notebooks/blob/main/TFLite_models_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBvox_bsvo6E"
      },
      "source": [
        "# Download TF Lite models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uktxe6ogqnYm",
        "outputId": "0db3167d-fee0-49bd-8ba1-3e97d33b8ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A0CuL6UerrbopTtDeHZWZmWnc8n4eC8c\n",
            "To: /content/model_age_nonq.tflite\n",
            "100% 4.28M/4.28M [00:00<00:00, 28.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A5YaEutUyJogCMBRGI5S4F3NbU0zVP6Q\n",
            "To: /content/model_age_q.tflite\n",
            "100% 2.14M/2.14M [00:00<00:00, 89.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A79vh_mAGn_AcPxyFO_y4E_RPS33ewZF\n",
            "To: /content/model_gender_nonq.tflite\n",
            "100% 1.32M/1.32M [00:00<00:00, 104MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ACrZlLeJc_OgCyHF93soPIZRBlR1HBRO\n",
            "To: /content/model_gender_q.tflite\n",
            "100% 668k/668k [00:00<00:00, 137MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --fuzzy 'https://drive.google.com/file/d/1A0CuL6UerrbopTtDeHZWZmWnc8n4eC8c/view'\n",
        "!gdown --fuzzy 'https://drive.google.com/file/d/1A5YaEutUyJogCMBRGI5S4F3NbU0zVP6Q/view'\n",
        "!gdown --fuzzy 'https://drive.google.com/file/d/1A79vh_mAGn_AcPxyFO_y4E_RPS33ewZF/view'\n",
        "!gdown --fuzzy 'https://drive.google.com/file/d/1ACrZlLeJc_OgCyHF93soPIZRBlR1HBRO/view'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-wAvtZDMiJZ"
      },
      "source": [
        "# Download UTKFace dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XRuzElFdYgU",
        "outputId": "8e9ac185-e341-4077-fe8e-bf3162aaa41b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jangedoo/utkface-new\n",
            "License(s): copyright-authors\n",
            "Downloading utkface-new.zip to /content\n",
            "100% 331M/331M [00:02<00:00, 167MB/s]\n",
            "100% 331M/331M [00:02<00:00, 156MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d jangedoo/utkface-new\n",
        "!unzip utkface-new.zip -d dataset > unzip.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-GP8r6oySHz"
      },
      "source": [
        "# Select a model to run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foPd813sFjlw",
        "outputId": "356d739b-9a0a-48d4-d803-ce8a3d26b55a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference on 23708 files/faces in UTKFace dataset...\n",
            "\n",
            "Inference time: 208.2 seconds\n",
            "Inference speed: 113.9 FPS\n",
            "\n",
            "MAE: 2.762 yrs\n",
            "RMSE: 4.259 yrs\n"
          ]
        }
      ],
      "source": [
        "Select = \"model_age_nonq.tflite\" # @param [\"model_age_nonq.tflite\", \"model_age_q.tflite\"]\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=Select)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "input_dtype = input_details[0]['dtype']\n",
        "\n",
        "import glob\n",
        "jpgs = glob.glob('dataset/UTKFace/*.jpg')\n",
        "print(f'Running inference on {len(jpgs)} files/faces in UTKFace dataset...')\n",
        "print()\n",
        "\n",
        "import time\n",
        "begin = time.time()\n",
        "y_true, y_pred = [], []\n",
        "for jpg in jpgs:\n",
        "    age, gender = map(int, jpg.split('/')[-1].split('_')[:2])\n",
        "    y_true.append(age)\n",
        "\n",
        "    # im = Image.open(jpg).resize(input_shape[1:3])\n",
        "    # image = np.asarray(im).astype(input_dtype) / 255\n",
        "    raw = tf.io.read_file(jpg)\n",
        "    image = tf.image.decode_jpeg(raw, channels=3)\n",
        "    image = tf.image.resize(image, input_shape[1:3]) / 255\n",
        "\n",
        "    # input_data = image.reshape(input_shape)\n",
        "    input_data = tf.reshape(image, input_shape)\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # The function `get_tensor()` returns a copy of the tensor data.\n",
        "    # Use `tensor()` in order to get a pointer to the tensor.\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    age_estimation = output_data[0][0] * 116\n",
        "    y_pred.append(age_estimation)\n",
        "\n",
        "elapsed = time.time() - begin\n",
        "print(f'Inference time: {elapsed:.1f} seconds')\n",
        "print(f'Inference speed: {len(jpgs)/elapsed:.1f} FPS')\n",
        "print()\n",
        "\n",
        "MAE = tf.keras.losses.MAE(y_true, y_pred).numpy()\n",
        "print(f'MAE: {MAE:.3f} yrs')\n",
        "RMSE = tf.keras.losses.MSE(y_true, y_pred).numpy() ** 0.5\n",
        "print(f'RMSE: {RMSE:.3f} yrs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AFNT4RpHB2r",
        "outputId": "da4a196c-884d-4923-cc30-6920450955fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference on 23708 files/faces in UTKFace dataset...\n",
            "\n",
            "Inference time: 203.8 seconds\n",
            "Inference speed: 116.3 FPS\n",
            "\n",
            "MAE: 2.763 yrs\n",
            "RMSE: 4.260 yrs\n"
          ]
        }
      ],
      "source": [
        "Select = \"model_age_q.tflite\" # @param [\"model_age_nonq.tflite\", \"model_age_q.tflite\"]\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=Select)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "input_dtype = input_details[0]['dtype']\n",
        "\n",
        "import glob\n",
        "jpgs = glob.glob('dataset/UTKFace/*.jpg')\n",
        "print(f'Running inference on {len(jpgs)} files/faces in UTKFace dataset...')\n",
        "print()\n",
        "\n",
        "import time\n",
        "begin = time.time()\n",
        "y_true, y_pred = [], []\n",
        "for jpg in jpgs:\n",
        "    age, gender = map(int, jpg.split('/')[-1].split('_')[:2])\n",
        "    y_true.append(age)\n",
        "\n",
        "    # im = Image.open(jpg).resize(input_shape[1:3])\n",
        "    # image = np.asarray(im).astype(input_dtype) / 255\n",
        "    raw = tf.io.read_file(jpg)\n",
        "    image = tf.image.decode_jpeg(raw, channels=3)\n",
        "    image = tf.image.resize(image, input_shape[1:3]) / 255\n",
        "\n",
        "    # input_data = image.reshape(input_shape)\n",
        "    input_data = tf.reshape(image, input_shape)\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # The function `get_tensor()` returns a copy of the tensor data.\n",
        "    # Use `tensor()` in order to get a pointer to the tensor.\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    age_estimation = output_data[0][0] * 116\n",
        "    y_pred.append(age_estimation)\n",
        "\n",
        "elapsed = time.time() - begin\n",
        "print(f'Inference time: {elapsed:.1f} seconds')\n",
        "print(f'Inference speed: {len(jpgs)/elapsed:.1f} FPS')\n",
        "print()\n",
        "\n",
        "MAE = tf.keras.losses.MAE(y_true, y_pred).numpy()\n",
        "print(f'MAE: {MAE:.3f} yrs')\n",
        "RMSE = tf.keras.losses.MSE(y_true, y_pred).numpy() ** 0.5\n",
        "print(f'RMSE: {RMSE:.3f} yrs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Czs9hXC8bBR",
        "outputId": "2303cadc-203e-4941-ba80-92a75d45386c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference on 23708 files/faces in UTKFace dataset...\n",
            "\n",
            "Inference time: 73.5 seconds\n",
            "Inference speed: 322.6 FPS\n",
            "\n",
            "Accuracy: 0.944\n"
          ]
        }
      ],
      "source": [
        "Select = \"model_gender_nonq.tflite\" # @param [\"model_gender_nonq.tflite\", \"model_gender_q.tflite\"]\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=Select)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "input_dtype = input_details[0]['dtype']\n",
        "\n",
        "import glob\n",
        "jpgs = glob.glob('dataset/UTKFace/*.jpg')\n",
        "print(f'Running inference on {len(jpgs)} files/faces in UTKFace dataset...')\n",
        "print()\n",
        "\n",
        "import time\n",
        "begin = time.time()\n",
        "y_true, y_pred = [], []\n",
        "for jpg in jpgs:\n",
        "    age, gender = map(int, jpg.split('/')[-1].split('_')[:2])\n",
        "    # y_true.append(age)\n",
        "    y_true.append(tf.one_hot(indices=gender, depth=2))\n",
        "\n",
        "    # im = Image.open(jpg).resize(input_shape[1:3])\n",
        "    # image = np.asarray(im).astype(input_dtype) / 255\n",
        "    raw = tf.io.read_file(jpg)\n",
        "    image = tf.image.decode_jpeg(raw, channels=3)\n",
        "    image = tf.image.resize(image, input_shape[1:3]) / 255\n",
        "\n",
        "    # input_data = image.reshape(input_shape)\n",
        "    input_data = tf.reshape(image, input_shape)\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # The function `get_tensor()` returns a copy of the tensor data.\n",
        "    # Use `tensor()` in order to get a pointer to the tensor.\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    # age_estimation = output_data[0][0] * 116\n",
        "    gender_classification = output_data[0]\n",
        "    # y_pred.append(age_estimation)\n",
        "    y_pred.append(gender_classification)\n",
        "\n",
        "elapsed = time.time() - begin\n",
        "print(f'Inference time: {elapsed:.1f} seconds')\n",
        "print(f'Inference speed: {len(jpgs)/elapsed:.1f} FPS')\n",
        "print()\n",
        "\n",
        "# MAE = tf.keras.losses.MAE(y_true, y_pred).numpy()\n",
        "# print(f'MAE: {MAE:.3f} yrs')\n",
        "# RMSE = tf.keras.losses.MSE(y_true, y_pred).numpy() ** 0.5\n",
        "# print(f'RMSE: {RMSE:.3f} yrs')\n",
        "accuracy = tf.metrics.categorical_accuracy(y_true, y_pred).numpy().sum() / len(jpgs)\n",
        "print(f'Accuracy: {accuracy:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK7ywQWH1c4C",
        "outputId": "c12b5238-58b7-4f9c-d70a-174f64042a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference on 23708 files/faces in UTKFace dataset...\n",
            "\n",
            "Inference time: 75.4 seconds\n",
            "Inference speed: 314.3 FPS\n",
            "\n",
            "Accuracy: 0.944\n"
          ]
        }
      ],
      "source": [
        "Select = \"model_gender_q.tflite\" # @param [\"model_gender_nonq.tflite\", \"model_gender_q.tflite\"]\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=Select)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "input_dtype = input_details[0]['dtype']\n",
        "\n",
        "import glob\n",
        "jpgs = glob.glob('dataset/UTKFace/*.jpg')\n",
        "print(f'Running inference on {len(jpgs)} files/faces in UTKFace dataset...')\n",
        "print()\n",
        "\n",
        "import time\n",
        "begin = time.time()\n",
        "y_true, y_pred = [], []\n",
        "for jpg in jpgs:\n",
        "    age, gender = map(int, jpg.split('/')[-1].split('_')[:2])\n",
        "    # y_true.append(age)\n",
        "    y_true.append(tf.one_hot(indices=gender, depth=2))\n",
        "\n",
        "    # im = Image.open(jpg).resize(input_shape[1:3])\n",
        "    # image = np.asarray(im).astype(input_dtype) / 255\n",
        "    raw = tf.io.read_file(jpg)\n",
        "    image = tf.image.decode_jpeg(raw, channels=3)\n",
        "    image = tf.image.resize(image, input_shape[1:3]) / 255\n",
        "\n",
        "    # input_data = image.reshape(input_shape)\n",
        "    input_data = tf.reshape(image, input_shape)\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # The function `get_tensor()` returns a copy of the tensor data.\n",
        "    # Use `tensor()` in order to get a pointer to the tensor.\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    # age_estimation = output_data[0][0] * 116\n",
        "    gender_classification = output_data[0]\n",
        "    # y_pred.append(age_estimation)\n",
        "    y_pred.append(gender_classification)\n",
        "\n",
        "elapsed = time.time() - begin\n",
        "print(f'Inference time: {elapsed:.1f} seconds')\n",
        "print(f'Inference speed: {len(jpgs)/elapsed:.1f} FPS')\n",
        "print()\n",
        "\n",
        "# MAE = tf.keras.losses.MAE(y_true, y_pred).numpy()\n",
        "# print(f'MAE: {MAE:.3f} yrs')\n",
        "# RMSE = tf.keras.losses.MSE(y_true, y_pred).numpy() ** 0.5\n",
        "# print(f'RMSE: {RMSE:.3f} yrs')\n",
        "accuracy = tf.metrics.categorical_accuracy(y_true, y_pred).numpy().sum() / len(jpgs)\n",
        "print(f'Accuracy: {accuracy:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukHpUjpI945i"
      },
      "source": [
        "# GPU spec for reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo33cXlt-wnv",
        "outputId": "83af9743-352c-4144-e96c-32a75ffa4b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-2e206b90-94e1-6dfd-4b29-fa1bfcfaa923)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
